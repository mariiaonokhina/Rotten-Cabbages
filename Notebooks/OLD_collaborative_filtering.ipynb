{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T0kcm4lKn3sz",
    "outputId": "a19d187e-94c6-4657-82ab-4f9fce18c6f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Merging and Cleaning complete.\n",
      "Current TMDB ID column type: int64\n",
      "\n",
      "Successfully created Clean TMDB Data.\n",
      "Saved to: clean_parsed_tmdb_5000.csv\n",
      "Final DataFrame shape: (4802, 21)\n",
      "The 'id' column is successfully preserved as a column.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast # Used sometimes if json.loads fails unexpectedly\n",
    "\n",
    "# --- PHASE 1: Loading, Merging, and Initial Cleaning ---\n",
    "\n",
    "# Merging the TMDB 5000 Movie Dataset and TMDB 5000 Credits Dataset\n",
    "movies_df = pd.read_csv('../Data/tmdb_5000_movies.csv')\n",
    "credits_df = pd.read_csv('../Data/tmdb_5000_credits.csv')\n",
    "\n",
    "# 1. Merge the two DataFrames on 'id' (from movies_df) and 'movie_id' (from credits_df)\n",
    "merged_df = pd.merge(movies_df, credits_df, left_on='id', right_on='movie_id', how='inner')\n",
    "\n",
    "# 2. Drop redundant and unnecessary columns\n",
    "merged_df.drop('movie_id', axis=1, inplace=True) # Redundant ID column\n",
    "merged_df.drop('title_y', axis=1, inplace=True) # Redundant title from credits file\n",
    "merged_df.drop('original_title', axis=1, inplace=True) # Keeping only English 'title'\n",
    "\n",
    "# 3. Rename columns for clarity\n",
    "merged_df = merged_df.rename(columns={'title_x': 'title'})\n",
    "\n",
    "# 4. Critical: Ensure 'id' remains a column, NOT an index.\n",
    "if merged_df.index.name == 'id':\n",
    "    merged_df.reset_index(inplace=True)\n",
    "\n",
    "# 5. Handle simple missing values\n",
    "merged_df['tagline'] = merged_df['tagline'].fillna('')\n",
    "merged_df['overview'] = merged_df['overview'].fillna('')\n",
    "merged_df['homepage'] = merged_df['homepage'].fillna('')\n",
    "\n",
    "# 6. Handle release_date and runtime\n",
    "merged_df['release_date'] = pd.to_datetime(merged_df['release_date'], errors='coerce')\n",
    "# Drop rows where release_date failed (1 missing row in original data)\n",
    "merged_df.dropna(subset=['release_date'], inplace=True)\n",
    "\n",
    "# Fill missing runtime with the median value\n",
    "merged_df['runtime'] = merged_df['runtime'].fillna(merged_df['runtime'].median())\n",
    "\n",
    "print(\"Initial Merging and Cleaning complete.\")\n",
    "print(f\"Current TMDB ID column type: {merged_df['id'].dtype}\")\n",
    "\n",
    "# --- PHASE 2: JSON Parsing and Flattening ---\n",
    "\n",
    "# Define a safe parser function for JSON columns (using ast.literal_eval as a fallback for safety)\n",
    "def safe_json_parse(json_string):\n",
    "    try:\n",
    "        # Tries standard JSON load\n",
    "        return json.loads(json_string)\n",
    "    except:\n",
    "        # Fallback for poorly formatted strings\n",
    "        try:\n",
    "            return ast.literal_eval(json_string)\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "# Helper function to extract and join names from JSON list\n",
    "def extract_names(json_list):\n",
    "    return ', '.join([item['name'] for item in json_list])\n",
    "\n",
    "# --- Apply Parsers ---\n",
    "\n",
    "# 1. Genres\n",
    "merged_df['genres'] = merged_df['genres'].apply(safe_json_parse).apply(extract_names)\n",
    "\n",
    "# 2. Keywords\n",
    "merged_df['keywords'] = merged_df['keywords'].apply(safe_json_parse).apply(extract_names)\n",
    "\n",
    "# 3. Production Companies\n",
    "merged_df['production_companies'] = merged_df['production_companies'].apply(safe_json_parse).apply(extract_names)\n",
    "\n",
    "# 4. Spoken Languages\n",
    "merged_df['spoken_languages'] = merged_df['spoken_languages'].apply(safe_json_parse).apply(extract_names)\n",
    "\n",
    "# 5. Production Countries\n",
    "merged_df['production_countries'] = merged_df['production_countries'].apply(safe_json_parse).apply(extract_names)\n",
    "\n",
    "# 6. Cast (Top 6 actors/actresses)\n",
    "def parse_cast_top_n(x, n=6):\n",
    "    cast = safe_json_parse(x)\n",
    "    return ', '.join([actor['name'] for actor in cast[:n]])\n",
    "merged_df['cast'] = merged_df['cast'].apply(parse_cast_top_n)\n",
    "\n",
    "# 7. Crew (All crew members with job description)\n",
    "def parse_crew_full(x):\n",
    "    crew = safe_json_parse(x)\n",
    "    return ', '.join([f\"{member['name']} ({member['job']})\" for member in crew])\n",
    "merged_df['crew'] = merged_df['crew'].apply(parse_crew_full)\n",
    "\n",
    "# --- PHASE 3: Final Save ---\n",
    "\n",
    "output_filename = 'clean_parsed_tmdb_5000.csv'\n",
    "\n",
    "# FINAL CHECK: Ensure 'id' is included in the saved file.\n",
    "merged_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"\\nSuccessfully created Clean TMDB Data.\")\n",
    "print(f\"Saved to: {output_filename}\")\n",
    "print(f\"Final DataFrame shape: {merged_df.shape}\")\n",
    "print(f\"The 'id' column is successfully preserved as a column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2kNFTYpBrscM",
    "outputId": "ea22e0ad-14ae-49c1-ce40-b68c2170ac18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not find one or both files (links.csv, ratings.csv).\n",
      "Please ensure the files are uploaded to the root directory of your Colab session.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'links_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     18\u001b[39m     exit()\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# --- Step 2: Clean and Prepare Links Data ---\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# links.csv contains movieId, imdbId, tmdbId.\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# We need 'movieId' to link with ratings and 'tmdbId' to link with the TMDB 5000 dataset.\u001b[39;00m\n\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Drop rows where tmdbId is missing, as we need this ID for joining with TMDB 5000.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mlinks_df\u001b[49m.dropna(subset=[\u001b[33m'\u001b[39m\u001b[33mtmdbId\u001b[39m\u001b[33m'\u001b[39m], inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Convert tmdbId to integer type (it's often stored as float due to NaNs)\u001b[39;00m\n\u001b[32m     28\u001b[39m links_df[\u001b[33m'\u001b[39m\u001b[33mtmdbId\u001b[39m\u001b[33m'\u001b[39m] = links_df[\u001b[33m'\u001b[39m\u001b[33mtmdbId\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'links_df' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import files # Used for displaying the files sidebar upload utility (optional, but helpful for context)\n",
    "\n",
    "# --- Step 1: Load Data ---\n",
    "LINKS_FILE = 'links.csv'\n",
    "RATINGS_FILE = 'ratings.csv'\n",
    "OUTPUT_FILE = 'ml_ratings_with_tmdb_id.csv'\n",
    "\n",
    "try:\n",
    "    # Read files directly from the current Colab directory\n",
    "    links_df = pd.read_csv(LINKS_FILE)\n",
    "    ratings_df = pd.read_csv(RATINGS_FILE)\n",
    "    print(\"MovieLens datasets loaded successfully from the Colab environment.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find one or both files ({LINKS_FILE}, {RATINGS_FILE}).\")\n",
    "    print(\"Please ensure the files are uploaded to the root directory of your Colab session.\")\n",
    "    # Exit execution if files are missing\n",
    "    exit()\n",
    "\n",
    "# --- Step 2: Clean and Prepare Links Data ---\n",
    "# links.csv contains movieId, imdbId, tmdbId.\n",
    "# We need 'movieId' to link with ratings and 'tmdbId' to link with the TMDB 5000 dataset.\n",
    "\n",
    "# Drop rows where tmdbId is missing, as we need this ID for joining with TMDB 5000.\n",
    "links_df.dropna(subset=['tmdbId'], inplace=True)\n",
    "\n",
    "# Convert tmdbId to integer type (it's often stored as float due to NaNs)\n",
    "links_df['tmdbId'] = links_df['tmdbId'].astype(int)\n",
    "\n",
    "# Select only the necessary columns\n",
    "links_cleaned = links_df[['movieId', 'tmdbId']]\n",
    "print(f\"Links data cleaned. Retained {links_cleaned.shape[0]} records with valid TMDB IDs.\")\n",
    "\n",
    "# --- Step 3: Clean and Prepare Ratings Data ---\n",
    "# ratings.csv contains userId, movieId, rating, timestamp.\n",
    "# For collaborative filtering, we primarily need userId, movieId, and rating.\n",
    "ratings_cleaned = ratings_df[['userId', 'movieId', 'rating']]\n",
    "print(f\"Ratings data cleaned. Retained {ratings_cleaned.shape[0]} rating records.\")\n",
    "\n",
    "# --- Step 4: Merge DataFrames ---\n",
    "# Merge the ratings data with the TMDB ID based on the common 'movieId'.\n",
    "# An inner merge ensures we only keep ratings for movies that have a valid tmdbId in the links file.\n",
    "merged_ratings_tmdb = pd.merge(\n",
    "    ratings_cleaned,\n",
    "    links_cleaned,\n",
    "    on='movieId',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Rename the tmdbId column to 'id' to match the column name in the 'clean_parsed_tmdb_5000.csv'\n",
    "merged_ratings_tmdb.rename(columns={'tmdbId': 'id'}, inplace=True)\n",
    "\n",
    "print(\"\\nMovieLens Ratings successfully merged with TMDB ID.\")\n",
    "print(f\"Final merged dataset shape: {merged_ratings_tmdb.shape}\")\n",
    "print(\"First 5 rows of the merged data:\")\n",
    "print(merged_ratings_tmdb.head())\n",
    "\n",
    "# --- Step 5: Save the Result ---\n",
    "# Save the new DataFrame containing userId, movieId, rating, and the TMDB 'id'.\n",
    "merged_ratings_tmdb.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nSuccessfully saved the final ratings-to-TMDB-ID mapping file to: {OUTPUT_FILE}\")\n",
    "print(\"This file can now be used for collaborative filtering or merged with your TMDB 5000 movie features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0PXgVwDRI6pc",
    "outputId": "20ae27f9-afbb-4a71-855d-f38fbc3e0cd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Mean Rating: 3.5016\n",
      "Using L2 Regularization factor: 0.005\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ movie_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_factors        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">30,500</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ movie_factors       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">485,800</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_user        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_factors[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_movie       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ movie_factors[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ latent_dot_product  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_user[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)               │                   │            │ flatten_movie[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_bias           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">610</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ movie_bias          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,716</span> │ movie_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_mean_add     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ latent_dot_produ… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_user_bias   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_bias[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_movie_bias  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ movie_bias[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ predicted_rating    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_mean_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │                   │            │ flatten_user_bia… │\n",
       "│                     │                   │            │ flatten_movie_bi… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ movie_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_factors        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │     \u001b[38;5;34m30,500\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ movie_factors       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │    \u001b[38;5;34m485,800\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_user        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ user_factors[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_movie       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ movie_factors[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ latent_dot_product  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ flatten_user[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDot\u001b[0m)               │                   │            │ flatten_movie[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_bias           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │        \u001b[38;5;34m610\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ movie_bias          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │      \u001b[38;5;34m9,716\u001b[0m │ movie_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_mean_add     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ latent_dot_produ… │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_user_bias   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ user_bias[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_movie_bias  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ movie_bias[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ predicted_rating    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ global_mean_add[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │                   │            │ flatten_user_bia… │\n",
       "│                     │                   │            │ flatten_movie_bi… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">526,626</span> (2.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m526,626\u001b[0m (2.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">526,626</span> (2.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m526,626\u001b[0m (2.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Enhanced Model Training ---\n",
      "Epoch 1/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - RMSE: 1.0197 - loss: 1.1776 - mae: 0.8123 - val_RMSE: 0.9785 - val_loss: 0.9928 - val_mae: 0.7767\n",
      "Epoch 2/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9768 - loss: 0.9945 - mae: 0.7764 - val_RMSE: 0.9672 - val_loss: 0.9859 - val_mae: 0.7667\n",
      "Epoch 3/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9687 - loss: 0.9904 - mae: 0.7696 - val_RMSE: 0.9646 - val_loss: 0.9853 - val_mae: 0.7647\n",
      "Epoch 4/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - RMSE: 0.9669 - loss: 0.9900 - mae: 0.7682 - val_RMSE: 0.9640 - val_loss: 0.9852 - val_mae: 0.7642\n",
      "Epoch 5/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9664 - loss: 0.9900 - mae: 0.7679 - val_RMSE: 0.9638 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 6/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - RMSE: 0.9662 - loss: 0.9900 - mae: 0.7678 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 7/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9662 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 8/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9662 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 9/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 10/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 11/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 12/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 13/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 14/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 15/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 16/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 17/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 18/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 19/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "Epoch 20/20\n",
      "\u001b[1m1261/1261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - RMSE: 0.9661 - loss: 0.9900 - mae: 0.7677 - val_RMSE: 0.9637 - val_loss: 0.9853 - val_mae: 0.7641\n",
      "\n",
      "--- Training Complete ---\n",
      "Final Test RMSE (Enhanced Model): 0.9637\n",
      "Final Test MAE (Enhanced Model): 0.7641\n",
      "Final Test MSE (Loss): 0.9853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "\n",
      "--- Specific Rating Prediction (Enhanced SVD Model) ---\n",
      "Predicted rating for User ID **1** and Movie ID **302**: **3.7455**\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Flatten, Add, Concatenate, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Configuration ---\n",
    "RATINGS_FILE = 'ml_ratings_with_tmdb_id.csv'\n",
    "LATENT_DIM = 50\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "SEED = 42\n",
    "REG_L2 = 0.005\n",
    "\n",
    "# Ensure reproducibility\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "try:\n",
    "    ratings_df = pd.read_csv(RATINGS_FILE)\n",
    "    # Use MovieLens movieId for encoding, as it's the original identifier for rating records\n",
    "    ratings = ratings_df[['userId', 'movieId', 'rating']]\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {RATINGS_FILE} not found. Using a smaller default dataset for demonstration.\")\n",
    "    data_url = \"http://files.grouplens.org/datasets/movielens/ml-latest-small/ratings.csv\"\n",
    "    ratings = pd.read_csv(data_url)\n",
    "    ratings = ratings[['userId', 'movieId', 'rating']]\n",
    "\n",
    "# --- 2. Prepare Data and Encoding ---\n",
    "# Convert original IDs to category codes (0 to N-1) for embedding layer indexing\n",
    "user_ids = ratings['userId'].astype('category').cat.codes\n",
    "movie_ids = ratings['movieId'].astype('category').cat.codes\n",
    "\n",
    "# Create mapping dictionaries to get original IDs back later\n",
    "user_map = dict(enumerate(ratings['userId'].astype('category').cat.categories))\n",
    "movie_map = dict(enumerate(ratings['movieId'].astype('category').cat.categories))\n",
    "\n",
    "num_users = len(user_ids.unique())\n",
    "num_movies = len(movie_ids.unique())\n",
    "global_mean = ratings['rating'].mean() # Calculate Global Mean (mu)\n",
    "\n",
    "X = pd.DataFrame({'user_id': user_ids, 'movie_id': movie_ids})\n",
    "y = ratings['rating'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "print(f\"Global Mean Rating: {global_mean:.4f}\")\n",
    "print(f\"Using L2 Regularization factor: {REG_L2}\")\n",
    "\n",
    "# --- 3. Build Keras Matrix Factorization Model with Biases and Regularization ---\n",
    "def build_svd_model_with_biases(num_users, num_movies, latent_dim, reg_l2, global_mean):\n",
    "\n",
    "    # --- Shared Components: User and Movie Inputs ---\n",
    "    user_input = Input(shape=(1,), name='user_input')\n",
    "    movie_input = Input(shape=(1,), name='movie_input')\n",
    "\n",
    "    # --- 1. User and Movie Embeddings (Latent Factors P and Q) with L2 Regularization ---\n",
    "    # User Embeddings (P)\n",
    "    user_embedding = Embedding(input_dim=num_users,\n",
    "                               output_dim=latent_dim,\n",
    "                               embeddings_regularizer=l2(reg_l2),\n",
    "                               name='user_factors')(user_input)\n",
    "    user_vec = Flatten(name='flatten_user')(user_embedding)\n",
    "\n",
    "    # Movie Embeddings (Q)\n",
    "    movie_embedding = Embedding(input_dim=num_movies,\n",
    "                                 output_dim=latent_dim,\n",
    "                                 embeddings_regularizer=l2(reg_l2),\n",
    "                                 name='movie_factors')(movie_input)\n",
    "    movie_vec = Flatten(name='flatten_movie')(movie_embedding)\n",
    "\n",
    "    # --- 2. User and Movie Biases (B_u and B_i) with L2 Regularization ---\n",
    "    # User Bias (b_u) - output_dim=1 for a scalar bias\n",
    "    user_bias = Embedding(input_dim=num_users,\n",
    "                              output_dim=1,\n",
    "                              embeddings_regularizer=l2(reg_l2),\n",
    "                              name='user_bias')(user_input)\n",
    "    user_bias_flat = Flatten(name='flatten_user_bias')(user_bias)\n",
    "\n",
    "    # Movie Bias (b_i) - output_dim=1 for a scalar bias\n",
    "    movie_bias = Embedding(input_dim=num_movies,\n",
    "                            output_dim=1,\n",
    "                            embeddings_regularizer=l2(reg_l2),\n",
    "                            name='movie_bias')(movie_input)\n",
    "    movie_bias_flat = Flatten(name='flatten_movie_bias')(movie_bias)\n",
    "\n",
    "    # --- 3. Prediction Formulation (SVD/Matrix Factorization Formula) ---\n",
    "    # R_hat = mu + b_u + b_i + P_u * Q_i^T\n",
    "\n",
    "    # P_u * Q_i^T (Dot product of latent factors)\n",
    "    latent_dot_product = Dot(axes=1, name='latent_dot_product')([user_vec, movie_vec])\n",
    "\n",
    "    # A layer representing the constant global mean (mu)\n",
    "    global_mean_layer = Lambda(lambda x: x + global_mean, name='global_mean_add')(latent_dot_product)\n",
    "\n",
    "    # Add the biases to the latent dot product and global mean\n",
    "    output = Add(name='predicted_rating')([global_mean_layer, user_bias_flat, movie_bias_flat])\n",
    "\n",
    "    # Build the model\n",
    "    model = Model(inputs=[user_input, movie_input], outputs=output)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(0.001),\n",
    "                  loss='mse',\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError(name='RMSE'), 'mae']) # Added MAE to metrics\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create and summarize the enhanced model\n",
    "model_svd = build_svd_model_with_biases(num_users, num_movies, LATENT_DIM, REG_L2, global_mean)\n",
    "model_svd.summary()\n",
    "\n",
    "\n",
    "# --- 4. Train the Model ---\n",
    "print(\"\\n--- Starting Enhanced Model Training ---\")\n",
    "\n",
    "# Train the model\n",
    "history = model_svd.fit(\n",
    "    [X_train['user_id'], X_train['movie_id']],\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=([X_test['user_id'], X_test['movie_id']], y_test)\n",
    ")\n",
    "\n",
    "print(\"\\n--- Training Complete ---\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "metrics = model_svd.evaluate([X_test['user_id'], X_test['movie_id']], y_test, verbose=0)\n",
    "loss = metrics[0] # MSE\n",
    "rmse = metrics[1] # RMSE\n",
    "mae = metrics[2] # MAE\n",
    "\n",
    "print(f\"Final Test RMSE (Enhanced Model): {rmse:.4f}\")\n",
    "print(f\"Final Test MAE (Enhanced Model): {mae:.4f}\")\n",
    "print(f\"Final Test MSE (Loss): {loss:.4f}\")\n",
    "\n",
    "\n",
    "# --- 5. Make a Prediction ---\n",
    "original_user_id = 1\n",
    "original_movie_id = 302\n",
    "\n",
    "try:\n",
    "    encoded_user_id = user_ids[ratings['userId'] == original_user_id].iloc[0]\n",
    "    encoded_movie_id = movie_ids[ratings['movieId'] == original_movie_id].iloc[0]\n",
    "except IndexError:\n",
    "    print(f\"\\nUser ID {original_user_id} or Movie ID {original_movie_id} not found in the training data.\")\n",
    "    encoded_user_id = X_test['user_id'].iloc[0]\n",
    "    encoded_movie_id = X_test['movie_id'].iloc[0]\n",
    "    original_user_id = user_map[encoded_user_id]\n",
    "    original_movie_id = movie_map[encoded_movie_id]\n",
    "    print(f\"Using test example: User ID {original_user_id}, Movie ID {original_movie_id}\")\n",
    "\n",
    "user_input_array = np.array([encoded_user_id])\n",
    "movie_input_array = np.array([encoded_movie_id])\n",
    "\n",
    "predicted_rating = model_svd.predict([user_input_array, movie_input_array])[0][0]\n",
    "\n",
    "print(f\"\\n--- Specific Rating Prediction (Enhanced SVD Model) ---\")\n",
    "print(f\"Predicted rating for User ID **{original_user_id}** and Movie ID **{original_movie_id}**: **{predicted_rating:.4f}**\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow (macOS)",
   "language": "python",
   "name": "tf-macos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
